{
    "data": "Gradient descent is an optimization technique used primarily for unconstrained problems. This first-order iterative method aims to minimize a multivariate function that is differentiable. The process involves repeatedly moving in the contrary direction of the gradient (or an estimated gradient) from the current point, since this leads to the steepest descent. In contrast, moving along the direction of the gradient will pursue the upward slope of the function, a practice known as gradient ascent. This method is especially beneficial in machine learning as it helps in reducing the cost or loss associated with a function.",
    "goal": "**Core Principle for Visualization:** The iterative process of gradient descent as it minimizes a differentiable multivariate function by moving in the opposite direction of the gradient.\n\n**Query:**\nCreate a visualization to explain the iterative process of gradient descent in minimizing a multivariate function. The goal is to clearly illustrate how the algorithm systematically moves against the gradient to reach the function's minimum, contrasting this with gradient ascent\u2014where movement follows the gradient up the slope. The visualization should include a series of graphs showing the function landscape, the gradient at various points, and the trajectory of points representing successive iterations of the gradient descent process. A line graph can effectively depict the progression of the function's value as it approaches the minimum. \n\nThis visual should aid in understanding the cause-and-effect relationship between the gradient and the movement direction, highlighting the concept of steepest descent and emphasizing the practical application in machine learning. \n\n**Objective:** Learners will deeply understand the gradient descent algorithm, including how it optimizes a multivariate function by employing iterative steps based on gradient direction, ultimately grasping its vital role in reducing cost or loss in machine learning applications.",
    "code": "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function: f(x, y) = (x^2 + y^2)\ndef f(x, y):\n    return x**2 + y**2\n\n# Gradient of the function\ndef gradient(x, y):\n    return np.array([2*x, 2*y])\n\n# Parameters for gradient descent\nlearning_rate = 0.1\ninitial_point = np.array([3.0, 3.0])\niterations = 10\npoints = [initial_point]\n\n# Perform gradient descent\nfor _ in range(iterations):\n    grad = gradient(points[-1][0], points[-1][1])\n    next_point = points[-1] - learning_rate * grad\n    points.append(next_point)\n\n# Create a grid for the function landscape\nx = np.linspace(-4, 4, 100)\ny = np.linspace(-4, 4, 100)\nX, Y = np.meshgrid(x, y)\nZ = f(X, Y)\n\n# Plotting the function landscape\nplt.figure(figsize=(12, 6))\n\n# 3D surface plot of the function\nax1 = plt.subplot(121, projection='3d')\nax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.6)\nax1.set_title('Function Landscape: f(x, y) = x\u00b2 + y\u00b2')\nax1.set_xlabel('X-axis')\nax1.set_ylabel('Y-axis')\nax1.set_zlabel('f(x, y)')\n\n# Trajectory of gradient descent\ntrajectory = np.array(points)\nax1.plot(trajectory[:, 0], trajectory[:, 1], f(trajectory[:, 0], trajectory[:, 1]), color='red', marker='o', label='Gradient Descent Trajectory')\nax1.legend()\n\n# 2D contour plot of the function\nax2 = plt.subplot(122)\ncontour = ax2.contour(X, Y, Z, levels=10, cmap='viridis')\nax2.set_title('Contour Plot of f(x, y)')\nax2.set_xlabel('X-axis')\nax2.set_ylabel('Y-axis')\nax2.clabel(contour, inline=True, fontsize=8)\n\n# Highlighting the trajectory in the contour plot\nax2.plot(trajectory[:, 0], trajectory[:, 1], color='red', marker='o', label='Gradient Descent Path')\nax2.legend()\n\n# Line graph showing progression towards the minimum\nfunction_values = [f(point[0], point[1]) for point in points]\nplt.figure(figsize=(6, 4))\nplt.plot(range(len(function_values)), function_values, marker='o', color='blue')\nplt.title('Progression of Function Value')\nplt.xlabel('Iteration')\nplt.ylabel('Function Value f(x, y)')\nplt.grid()\n\n# Final adjustments to the plots\nplt.tight_layout()\n```"
}